---
title: "Final Project"
author: "Grace Wagner and Nathanael Kovscek"
date: "2023-04-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Front Matter

```{r, message= FALSE}
rm(list = ls())
library(tidyverse)
library(ggplot2)
library(lubridate)
library(randomForest)
library(FNN)
library(e1071)

CODGameModes <- read.csv("~/Documents/github/STAT380/data/CODGameModes.csv")
CODGames_p1_380 <- read.csv("~/Documents/github/STAT380/data/CODGames_p1_380.csv")
CODGames_p2_380 <- read.csv("~/Documents/github/STAT380/data/CODGames_p2_380.csv")
CODMaps <- read.csv("~/Documents/github/STAT380/data/CODMaps.csv")
```

## Task 1: Which maps are the most likely to win the map vote?

Research Question: Which maps are the most likely to win the map vote?

How I Plan to Answer this Question:

I will first make sure I append the CODGames_p1_380 and CODGames_p2_380 datasets, making sure to keep all of the observations, to make a complete dataset of the votes and maps selected. Then I will identify which votes ended in a tie. I will store this data separaetly from the data where a normal vote took place since Map1 is always chosen when there is a tie. 
To do this I plan to make another dataset that is made from the filtered out the rows that have no values in the MapVote column. Next I will identify how many times each map was chosen in a tie by summarizing the data and grouping by Choice making sure to add a N() value so that the number of times each Map was chosen is in the summary. I will repeat the summary and group_by steps for the dataset containing of regular votes. From there I will take the information from the two summaries, combine them, and make a visualization that shwos the results. To represent the results from ties, and from regular votes, I want to make sure that it is shown which maps were chosen from ties. To do this, I would like to make a barchart that is made of two colors and a key, one color will represnt regular votes and the other will represent results from tied votes.

First, I will add concatenate the cases of player one and player two together. Then, I will filter out the ties, select features relevant to the present question, and assign this filtered table to a new variable called map_stats.

```{r}
# concatenate player results datasets
all_games <- CODGames_p1_380 %>% bind_rows(CODGames_p2_380)

#filter out NAN values and select only columns relevant to the question
map_stats <- all_games %>% 
  select(Map1, Map2, Choice, MapVote) %>% 
  filter(MapVote != "")
```

Now, I want to fix the names of all misspelled maps

```{r}
# Find all maps that need to be renamed ----
# Put all names into a list. CODMaps$Name
uni_names <- union(unique(map_stats$Map1), unique(map_stats$Map2))
uni_names <- union(uni_names, unique(map_stats$Choice))
# Find the symmetric difference, these are the bad values
setdiff(uni_names, CODMaps$Name)
```

There are 21 misspelled map names!

Update Map1 names

```{r}
# View names that need changing
# setdiff(unique(map_stats$Map1), CODMaps$Name)

map_stats$Map1[map_stats$Map1 == "Jungle "] <- "Jungle"
map_stats$Map1[map_stats$Map1 == "Ruah"] <- "Rush"
map_stats$Map1[map_stats$Map1 == "Collateral"] <- "Collateral Strike"
map_stats$Map1[map_stats$Map1 == "Riad"] <- "Rush"
map_stats$Map1[map_stats$Map1 == "Miami "] <- "Miami"
map_stats$Map1[map_stats$Map1 == "Collateral Striek"] <- "Collateral Strike"
map_stats$Map1[map_stats$Map1 == "Miami Stirke"] <- "Miami Strike"
map_stats$Map1[map_stats$Map1 == "Collaterol Strike"] <- "Collateral Strike"
map_stats$Map1[map_stats$Map1 == "Drive-in"] <- "Drive-In"
map_stats$Map1[map_stats$Map1 == "Deprogam"] <- "Deprogram"
map_stats$Map1[map_stats$Map1 == "Rush "] <- "Rush"
map_stats$Map1[map_stats$Map1 == "Zoo "] <- "Zoo"
map_stats$Map1[map_stats$Map1 == "Raid "] <- "Raid"
```

Update Map2 names

```{r}
# setdiff(unique(map_stats$Map2), CODMaps$Name)

map_stats$Map2[map_stats$Map2 == "Miami Stirke" ] <- "Miami Strike"
map_stats$Map2[map_stats$Map2 == "Collateral" ] <- "Collateral Strike"
map_stats$Map2[map_stats$Map2 == "yamantau"] <- "Yamantau"
map_stats$Map2[map_stats$Map2 == "Drive-in" ] <- "Drive-In"
map_stats$Map2[map_stats$Map2 == "Nuketown '84 Halloween" ] <- "Nuketown '84"
map_stats$Map2[map_stats$Map2 == "Miami Sstrike" ] <- "Miami Strike"
map_stats$Map2[map_stats$Map2 == "Amrada Strike" ] <- "Armada Strike"

```


Update Choice names

```{r}
map_stats$Choice[map_stats$Choice == "APocalypse"] <- "Apocalypse"
map_stats$Choice[map_stats$Choice == "Apocolypse"] <- "Apocalypse"
map_stats$Choice[map_stats$Choice == "Drive-in"] <- "Drive-In"
map_stats$Choice[map_stats$Choice == "Collateral"] <- "Collateral Strike"
map_stats$Choice[map_stats$Choice == "Collaterel Strike"] <- "Collateral Strike"
map_stats$Choice[map_stats$Choice == "Deisel"] <- "Diesel"
map_stats$Choice[map_stats$Choice == "Nuketown '84 Halloween"] <- "Nuketown '84"
```




```{r}
CODMaps <- CODMaps %>% separate(Date, into = c("month", "day", "year"), sep = "/", convert = TRUE)
CODMaps <- CODMaps %>% 
  rename(Choice = Name)

CODMaps$year[CODMaps$year == "20"] <-  2020
CODMaps$year[CODMaps$year == "21"] <-  2021
CODMaps$year[CODMaps$year == "22"] <-  2022
  

# Join CODMaps so season variables are present for analysis
map_stats <- map_stats %>% inner_join(CODMaps, by = "Choice")
```

```{r}
ggplot(data = map_stats, mapping = aes(x = reorder(Choice, Choice, function(x)-length(x)), fill = as.factor(year))) + 
  geom_bar() + 
  labs(title = "Chosen Maps and their Selection Frequency",
       y = "Frequency",
       x = "Map Choice",
       fill = "Map Release Year") +
  theme(axis.text.x = element_text(angle = 90))
```
Split the vote feature into the votes for the first and votes for the second.

```{r, warning=FALSE}
map_stats <- map_stats %>% separate(MapVote, into = c("FirstV", "SecondV"), sep = " to ", convert = TRUE) %>% 
  na.omit()
```

What percentage of the map choices were ties?

```{r}
map_stats <- map_stats %>% mutate(Tie = if_else(FirstV == SecondV, "Tie", "No Tie"))

ties <- map_stats %>% 
  group_by(Tie) %>% 
  summarize(n = as.factor(n()))

ggplot(ties, aes(x="", y=n, fill = Tie)) +
  geom_bar(stat="identity", width=1) +
  coord_polar("y", start=0) +
  geom_text(aes(label = paste0(n)), position = position_stack(vjust = .8, reverse = TRUE)) +
  theme_void() +
  labs(title = "Proportion of Tie Votes",
    x = NULL,
       y = NULL,
       fill = "Vote Status") +
  scale_fill_manual(values=c("#09626F", "gold2"))

```

Count total times a map has won were it was not a tie:

```{r}

map_stats <- map_stats %>% 
  filter(Tie == "Tie")

# Count number of appearances of a map in the first position
map1_votes <- map_stats %>% group_by(Map1) %>% 
  summarize(N1 = n())

# Count number of appearances of a map in the second position
map2_votes <- map_stats %>% group_by(Map2) %>% 
  summarize(N2 = n())

# Rename their columns to be the same for joining
names(map2_votes)[1] <- "Map"
names(map1_votes)[1] <- "Map"

# Join tables with map appearance counts
# Find total appearances
map_totals <- map2_votes %>% full_join(map1_votes, by = "Map") %>% 
  mutate(N1 = replace_na(N1, 0),
         N2 = replace_na(N2, 0),
         TotalV = (N1 + N2)
)

# Find proportion of times a map was choosen (without being a tie)
total_games <- sum(map_totals$TotalV)/2
map_totals <- map_totals %>% mutate(OverallProp = (TotalV/total_games))
```


```{r}

CODMaps <- CODMaps %>% rename(Map = Choice)

map_totals <- map_totals %>% full_join(CODMaps, by = "Map")

ggplot(map_totals, aes(y = OverallProp, x = reorder(Map, OverallProp, decreasing = TRUE), fill = as.factor(year))) +
  geom_col() +
  labs(title = "Favorite Maps",
       subtitle = "Showed by year map was first available",
       x = "Map Name",
       y = "Proportion of Map Vote Wins",
       fill = "Year Released") +
  # scale_fill_brewer(palette="Set1") +
  theme(axis.text.x = element_text(angle = 90))
```


Join this table with the CODMaps table and visualize season preferences.


```{r}

favorite_season <- map_totals %>% 
  group_by(FirstAvailable) %>% 
  summarize(SeasonProp = sum(OverallProp))

ggplot(favorite_season, aes(y = SeasonProp, x = reorder(FirstAvailable, SeasonProp, decreasing = TRUE), fill = FirstAvailable)) +
  geom_col() +
  labs(title = "Favorite Maps by Season",
       subtitle = "Ties not included",
       x = "Map Available Category",
       y = "Proportion of Map Vote Wins",
       fill = "First Available") +
  scale_fill_brewer(palette="Set1") +
  theme(axis.text.x = element_text(angle = 90))

```

## Task 2

Research Question: How does the game type affect TotalXP after accounting for the Score?

### Step1 - Clean column values for game type

```{r}
# List all unique game type values
# Locate all spellings
# unique(all_games$GameType)

# Update values
all_games$GameType[all_games$GameType == "HC - TDM" ] <- "TDM"
all_games$GameType[all_games$GameType == "HC - Kill Confirmed" ] <- "Kill_Confirmed"
all_games$GameType[all_games$GameType == "Kill Confirmed" ] <- "Kill_Confirmed"
all_games$GameType[all_games$GameType == "HC - Hardpoint" ] <- "Hardpoint"
all_games$GameType[all_games$GameType == "HC - Domination" ] <- "Domination"

# List values to display naming convention uniformity
unique(all_games$GameType)

```

### Step2 - EDA

```{r}
# Remove score null values from the dataset

all_games <- all_games[!(is.na(all_games$Score)), ]

# Create a table with summary statistics of score by game type
all_games %>% 
  group_by(GameType) %>% 
  summarize(count = n(),
    ScoreMean = mean(Score),
    ScoreMedian = median(Score),
    Scoresd = sd(Score),
    Scoremin = min(Score),
    Scoremax = max(Score))
```

```{r}
ggplot(all_games, mapping = aes(y = Score, x = GameType)) +
  geom_boxplot() +
  labs(title = "Distribution of Score by Game Type",
       x = "Game Type",
       y = "Player Score") +
  theme_light()
```

```{r}
# Create a scatterplot of Score and TotalXP
# Facet by GameType

ggplot(all_games, mapping = aes(x = Score, TotalXP)) +
  geom_point() + 
  geom_smooth(method = lm, se = FALSE) +
  facet_grid(. ~ GameType) +
  facet_wrap(. ~ GameType, ncol = 2) +
  labs(title = "Total Experience Point by Player Score",
       subtitle = "Grouped by Game Type",
       x = "Player Score",
       y = "Total Experience Earned") +
  theme_light() +
  theme(strip.text.x = element_text(color = "black"))
```

### Step3 - Build a model

```{r}
# Build indicator variables for gametype
all_games <- all_games %>% 
  mutate(TDM = if_else(GameType == "TDM", 1, 0),
  Hardpoint = if_else(GameType == "Hardpoint", 1, 0),
  Domination = if_else(GameType == "Domination", 1, 0),
  Kill_Confirmed = if_else(GameType == "Kill_Confirmed", 1, 0)
  )


model <- lm(TotalXP ~ TDM + Hardpoint + Domination + Kill_Confirmed + Score, all_games)

```

The following model describes the relationship

$$\hat{y}_i = `r round(model[["coefficients"]][1], digits=3)` + `r round(model[["coefficients"]][2], digits = 3)`x_{i, TDM} + `r round(model[["coefficients"]][3], digits = 3)`x_{i, Hardpoint} + `r round(model[["coefficients"]][4], digits = 3)`x_{i, Domination} + `r round(model[["coefficients"]][6], digits = 3)`x_{i, Score}$$
## Task 3

Research Question: Can we predict weapon based on the score?

```{r}
x <- all_games %>% group_by(PrimaryWeapon) %>% 
  summarize(
    n = n()
  )
x$n <- x$n[order(x$n)]
x
```

```{r}
sum(is.na(all_games$top5Weapons))
```

```{r}
all_games <- all_games %>%
  filter(PrimaryWeapon != "")

all_games <- all_games %>%
  mutate(top5Weapons = ifelse(PrimaryWeapon == "XM4"| PrimaryWeapon == "Type 63" | PrimaryWeapon == "ShadowHunter" | PrimaryWeapon == "RPD" | PrimaryWeapon == "QBZ-83", 1, 0))
```

```{r}
#Random Forest
set.seed(123)
train_ind <-sample(1:nrow(all_games), floor(0.8 * nrow(all_games)))

Train <- all_games[train_ind, ]
Test <- all_games[-train_ind, ]

rf <- randomForest(as.factor(top5Weapons) ~ Score, data = Train, ntree = 500, mtry = 1)

pred_prob_rf <- predict(rf, newdata = Test, type = "prob")

pred_surv_rf <- predict(rf, newdata = Test, type = "response")

mean(pred_surv_rf == Test$top5Weapons) #calculate accuracy

set.seed(NULL)
```

```{r}
#KNN
xvars <- c("Score")
all_games2 <- all_games
all_games2[ , xvars] <- scale(all_games2[ , xvars], center = TRUE, scale = TRUE)

set.seed(123)
train_ind2 <- sample(1:nrow(all_games2), floor(0.8 * nrow(all_games2)))

Train2 <- all_games2[train_ind2, ]
Test2 <- all_games2[-train_ind2, ]

knn_res <- knn(train = Train2[ ,xvars, drop = FALSE],
               test = Test2[ , xvars, drop = FALSE],
               cl = Train2$top5Weapons,
               k = 3)

Test2 <- Test2 %>%
  mutate(pred_top5Weapons = knn_res)

mean(Test2$top5Weapons == Test2$pred_top5Weapons) #calculate accuracy

set.seed(NULL)
```


```{r}
#Naive Bayes
set.seed(123)
train_ind3 <- sample(1:nrow(all_games), floor(0.8 * nrow(all_games)))

Train3 <- all_games[train_ind3, ]
Test3 <- all_games[-train_ind3, ]

model <- naiveBayes(top5Weapons ~ Score, data = Train3)
pred_bayes <- predict(model, Test3)

mean(pred_bayes == Test3$top5Weapons) #calculate accuracy
set.seed(NULL)
```

Research Question: Can we predict weapon based on the score?

The three methods I used in this section are Random Forest (listed in problem), KNN (2nd chosen from class), and Naive Bayes (not gone over in class). I decided to use Naive Bayes because I found a lot of information about it online, in the textbook, and the top5Weapons variable we created for this problem has 2 levels which is ideal for Naive Bayes. We created the top5Weapons variable to classify the Weapons from the data set. Since there are many different weapons, which would require multiple classifiers, we decided it would be better for the models and our question to create a variable that represents the top 5 weapons that are used. So, we made sure that there were no NA values, created a table to find the top 5 weapons used, then made a classifier based on the results of the table. I made sure to keep the training testing split the same percentage between models so that they could be fairly compared. I also created a new data set in the KNN model to represent the one we were using in the other models so that the scaling wouldn't effect the original data set and mess up the results of the other models. 

After running all of the models and finding their accuracy, it appears that the Naive Bayes model performed the best of the three. Naive Bayes had the largest accuracy, 0.8703704, while Random Forest had an accuracy of 0.8395062, and KNN had an accuracy of 0.8148148. So, it is safe to say that we can predict that the weapon used was one of the top 5 most popular weapons based on the score with a nearly 87% accuracy using the Naive Bayes model. 
